student:
  model_name: resnet   #resnet50
  student_keys: [res5, res4]   #keep
  checkpoint_path: /home/arda/dinov2/distillation/checkpoints/resnet50.pth # keep



teacher:
  model_name: dinov2_vits14



data_transform:
  n_global_crops: 2
  n_local_crops: 8
  global_crops_scale: [0.32, 1.0]
  local_crops_scale: [0.05, 0.32]
  global_crops_size: [224, 224]
  local_crops_size: [224, 224]




optimizer:
  type: AdamW
  kwargs:
    lr: 2.5e-4
    betas: [0.9, 0.999]
    weight_decay: 0.05
  scheduler:
    type: CosineAnnealingLR
    kwargs:
      T_max: 30
      eta_min: 2.5e-5
    monitor: val_loss
    interval: epoch
    frequency: 1

loss:
  losses:
    - type: scalekd
      weight: 1
      kwargs:
        alpha: [0.08, 0.06]
        student_dims: 1024 #remove
        teacher_dims: 384 #remove
        query_hw: [16, 16] #remove
        pos_hw: [16, 16] #remove
        pos_dims: 384 #remove
        window_shapes: [1, 1]
        self_query: True
        softmax_scale: [5.0, 5.0]
        dis_freq: high
        num_heads: 16
        name: scalekd_n
        use_this: true
    - type: scalekd
      weight: 1.0
      kwargs:
        alpha: [0.08, 0.06]
        student_dims: 2048
        teacher_dims: 384
        query_hw: [16, 16]
        pos_hw: [16, 16]
        pos_dims: 384
        window_shapes: [1, 1]
        self_query: False
        softmax_scale: [5.0, 5.0]
        dis_freq: high
        num_heads: 24
        name: scalekd_last
        use_this: true

    # - type: dinoiser
    #   weight: 1.0
    #   kwargs:
    #     student_dims: 2048
    #     teacher_dims: 1536



train:
  name: resnet50
  max_epochs: 10
  accelerator: gpu
  devices: [0,1]
  num_nodes: 1
  strategy: ddp
  # resume_from_checkpoint: "/path/to/your/checkpoint.ckpt"  # Add this line
data_loader:
  data_dir: /storage/disk2/sam_resized
  batch_size: 64
  num_workers: 8
  


# feature_matcher:
#   res5:
#     out_channels: 2048
#     kernel_size: 1
#     stride: 1
#     padding: 0
#   res4:
#     out_channels: 1024
#     kernel_size: 3
#     stride: 1
#     padding: 1


checkpoints:
  dirpath: checkpoints
  monitor: val_loss
  mode: max
  save_top_k: 3


wandb:
  project: "dinov2-distillation"  # Project name in W&B
  name: resnet50  # Run name (will use train.name if null)
  tags: ["distillation", "resnet", "dinov2"]  # Searchable tags
  notes: "Knowledge distillation from DINOv2 to ResNet50"  # Run description

